# CrewAI task configuration – Crossnection MVP (8 tasks)
# Each task is atomic, idempotent and mapped to one of the three agents.

# ─────────────────────────────────────────────────────────────────────────────
# DATA AGENT TASKS
# ─────────────────────────────────────────────────────────────────────────────

profile_validate_dataset:
  agent: data_agent
  description: |
    Profile each uploaded CSV, validate schema consistency, detect missing
    values and basic anomalies. Produce a structured `data_report.json` summarising findings.
  input:
    csv_folder: "examples/driver_csvs"  # Default hardcoded
    _original_csv_folder: "{{ csv_folder }}"  # Mantieni riferimento originale
    kpi: "{{ kpi }}"
    mode: "full_pipeline"
  output_key: data_report_ref  # Riferimento al file nel Context Store
  expected_output: >
    A reference to a JSON report with schema validation results stored in Context Store.

join_key_strategy:
  agent: data_agent
  description: |
    Analyze data_report to discover or generate a unique join-key
    that can correlate all driver datasets. If no clear key, propose matching rules.
  input_key:
    - data_report_ref  # Riferimento al file nel Context Store
  output_key: join_key_strategy_ref
  expected_output: >
    A reference to a strategy object defining the join key stored in Context Store.

clean_normalize_dataset:
  agent: data_agent
  description: |
    Apply cleaning rules (imputations, type conversions) and merge all driver
    datasets into a single table using the join-key strategy.
  input_key:
    - join_key_strategy_ref
    - data_report_ref
  output_key: unified_dataset_ref
  expected_output: >
    A reference to a cleaned, normalized dataset stored in Context Store, ready for analysis.

# ─────────────────────────────────────────────────────────────────────────────
# STATS AGENT TASKS
# ─────────────────────────────────────────────────────────────────────────────

compute_correlations:
  agent: stats_agent
  description: |
    Compute pairwise statistical correlations between each driver and the KPI,
    including significance tests. The output MUST include 'r' and 'p_value' fields
    for each driver, and be saved in the Context Store as 'correlation_matrix'.
  input:
    df_csv: "{{ unified_dataset_ref }}"  # Riferimento al Context Store
    mode: "correlation"
    kpi: "value_speed"  # Default KPI if user doesn't specify
  output_key: correlation_matrix_ref
  expected_output: >
    A reference to a JSON array with driver names, correlation coefficients, and p-values.

rank_impact:
  agent: stats_agent
  description: |
    Rank drivers by their impact on the KPI based on correlation strength
    and statistical significance.
  input:
    df_csv: "{{ unified_dataset_ref }}"  # Riferimento al Context Store
    kpi: "value_speed"  # Default KPI if user doesn't specify 
    mode: "ranking"
    correlation_matrix: "{{ correlation_matrix_ref }}"  # Riferimento al Context Store
  output_key: impact_ranking_ref
  expected_output: >
    A reference to a ranked list of drivers by their impact on the KPI.

detect_outliers:
  agent: stats_agent
  description: |
    Identify outliers in the driver datasets using the cross_stat_engine tool
    with the specific parameters:
    - df_csv: The unified dataset (from context store)
    - kpi: The name of the KPI column (default "value_speed")
    - mode: Must be exactly "outliers" (not "outlier detection")
    
    The output MUST include an 'outliers' array, even if empty,
    and be saved in the Context Store as 'outlier_report'.
  input:
    df_csv: "{{ unified_dataset_ref }}"  # Riferimento al Context Store
    kpi: "value_speed"  # Default KPI
    mode: "outliers"
  output_key: outlier_report_ref
  expected_output: >
    A reference to a JSON report identifying outliers in driver datasets.

# ─────────────────────────────────────────────────────────────────────────────
# EXPLAIN AGENT TASKS
# ─────────────────────────────────────────────────────────────────────────────

draft_root_cause_narrative:
  agent: explain_agent
  description: |
    Generate a draft narrative of the top root causes, combining impact_ranking
    and outlier_report into coherent insights.
  input_key:
    - impact_ranking_ref  # Riferimento al Context Store
    - outlier_report_ref  # Riferimento al Context Store
  output_key: narrative_draft_ref
  human_input: true
  expected_output: >
    A reference to a markdown-formatted draft report listing prioritized root causes.

finalize_root_cause_report:
  agent: explain_agent
  description: |
    Incorporate user feedback from the draft phase and produce the final
    validated root-cause report.
  input_key: narrative_draft_ref  # Riferimento al Context Store
  output_key: root_cause_report_ref
  expected_output: >
    A reference to a finalized report of root causes, ready for export or UI rendering.